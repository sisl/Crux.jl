using Crux, Flux, POMDPGym, Random, POMDPs, BSON

## Cartpole
mdp = GymPOMDP(:CartPole, version = :v0)
as = actions(mdp)
S = state_space(mdp)

Disc() = ContinuousNetwork(Chain(Dense(6, 64, relu), Dense(64, 64, relu), Dense(64, 1)))
V() = ContinuousNetwork(Chain(Dense(4, 64, relu), Dense(64, 64, relu), Dense(64, 1)))
A() = DiscreteNetwork(Chain(Dense(4, 64, relu), Dense(64, 64, relu), Dense(64, length(as))), as)

# Fill a buffer with expert trajectories
expert_trajectories = BSON.load("examples/il/expert_data/cartpole.bson")[:data]

# Solve with PPO-GAIL
Î³ = Float32(discount(mdp))
ğ’®_gail = OnPolicyGAIL(D=Disc(), Î³=Î³, gan_loss=GAN_BCELoss(), ğ’Ÿ_demo=expert_trajectories, solver=PPO, Ï€=ActorCritic(A(), V()), S=S, N=40000, Î”N=1024, d_opt=(batch_size=1024, epochs=80))
solve(ğ’®_gail, mdp)

# Solve with Behavioral Cloning
ğ’®_bc = BC(Ï€=A(), ğ’Ÿ_demo=expert_trajectories, S=S, opt=(epochs=100,), log=(period=10,))
N = solve(ğ’®_bc, mdp)

# Solve with IQ-Learn
