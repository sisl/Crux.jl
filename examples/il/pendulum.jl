using POMDPs, Crux, Flux, POMDPGym, BSON
import POMDPPolicies:FunctionPolicy
import Distributions:Uniform
using Random
using Distributions

## Pendulum
mdp = PendulumMDP()
as = [actions(mdp)...]
amin = [-1f0]
amax = [1f0]
rand_policy = FunctionPolicy((s) -> Float32.(rand.(Uniform.(amin, amax))))
S = state_space(mdp, Ïƒ=[6.3f0, 8f0])

# get expert trajectories
expert_trajectories = BSON.load("/home/anthonycorso/.julia/dev/Crux/examples/il/expert_data/pendulum.bson")[:data]
expert_perf = sum(expert_trajectories[:r]) / length(episodes(expert_trajectories))
expert_trajectories[:r] .=1

# Define the networks we will use
QSA() = ContinuousNetwork(Chain(Dense(3, 64, relu), Dense(64, 64, relu), Dense(64, 1)))
QSA_SN() = ContinuousNetwork(Chain(DenseSN(3, 64, relu), DenseSN(64, 64, relu), DenseSN(64, 1)))
V() = ContinuousNetwork(Chain(Dense(2, 64, relu), Dense(64, 64, relu), Dense(64, 1)))
A() = ContinuousNetwork(Chain(Dense(2, 64, relu, init=Flux.orthogonal), Dense(64, 64, relu, init=Flux.orthogonal), Dense(64, 1, tanh, init=Flux.orthogonal), x -> 2f0 * x), 1)
G() = GaussianPolicy(A(), zeros(Float32, 1))

function SAC_A()
    base = Chain(x -> x ./ [6.3f0, 8f0], Dense(2, 64, relu), Dense(64, 64, relu))
    mu = ContinuousNetwork(Chain(base..., Dense(64, 1)))
    logÎ£ = ContinuousNetwork(Chain(base..., Dense(64, 1)))
    SquashedGaussianPolicy(mu, logÎ£)
end

# This currently doesn't work for some reason
ğ’®_gail = GAIL(D=QSA_SN(), gan_loss=GAN_BCELoss(), ğ’Ÿ_demo=expert_trajectories, solver=PPO, Ï€=ActorCritic(G(), V()), S=S, N=1000000, Î”N=1024)
solve(ğ’®_gail, mdp)

ğ’®_bc = BC(Ï€=A(), ğ’Ÿ_demo=expert_trajectories, S=S, opt=(epochs=100,), log=(period=10,))
solve(ğ’®_bc, mdp)

ğ’®_advil = AdVIL(Ï€=ActorCritic(A(),QSA()), ğ’Ÿ_demo=expert_trajectories, S=S, a_opt=(epochs=1000, optimizer=ADAM(8f-4), batch_size=1024), c_opt=(optimizer=ADAM(8e-4),), max_steps=100, log=(period=10,))
solve(ğ’®_advil, mdp)


ğ’®_sqil = SQIL(Ï€=ActorCritic(SAC_A(), DoubleNetwork(QSA(), QSA())), 
              S=S,
              ğ’Ÿ_demo=expert_trajectories,
              max_steps=100,
              N=30000,
              buffer_size=Int(1e4),
              c_opt=(batch_size=128, optimizer=ADAM(1e-3)),
              a_opt=(batch_size=128, optimizer=ADAM(1e-3)),
              Ï€_explore=GaussianNoiseExplorationPolicy(0.2f0, a_min=[-2.0], a_max=[2.0]))

solve(ğ’®_sqil, mdp)

Crux.set_crux_warnings(false)
ğ’®_adril = AdRIL(Ï€=ActorCritic(SAC_A(), DoubleNetwork(QSA(), QSA())), 
              S=S,
              ğ’Ÿ_demo=expert_trajectories,
              max_steps=100,
              N=30000,
              buffer_size=Int(1e4),
              c_opt=(batch_size=128, optimizer=ADAM(1e-3)),
              a_opt=(batch_size=128, optimizer=ADAM(1e-3)),
              Ï€_explore=GaussianNoiseExplorationPolicy(0.2f0, a_min=[-2.0], a_max=[2.0]))

solve(ğ’®_adril, mdp)


ğ’®_ASAF = ASAF(Ï€=G(), 
              S=S, 
              Î”N=2000, 
              ğ’Ÿ_demo=expert_trajectories,
              N=50000,
              max_steps=100,
              a_opt=(batch_size=256, optimizer=Flux.Optimise.Optimiser(Flux.ClipValue(1f0), ADAM(1e-3)), epochs=10))

solve(ğ’®_ASAF, mdp)

using Plots
p = plot_learning([ğ’®_gail, ğ’®_bc, ğ’®_advil, ğ’®_sqil, ğ’®_ASAF], title="Pendulum Swingup Imitation Learning Curves", labels=["GAIL", "BC", "AdVIL", "SQIL", "AdRIL", "ASAF"], legend=:right)
plot!(p, [1,100000], [expert_perf, expert_perf], color=:black, label="expert")

savefig("pendulum_benchmark.pdf")

