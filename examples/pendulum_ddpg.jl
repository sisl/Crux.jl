using Revise
using POMDPs, Crux, Flux, POMDPGym

## Pendulum
mdp = PendulumMDP(actions=[-2., -0.5, 0, 0.5, 2.]) # Continuous
# mdp = ContinuousBanditMDP(2.0) # Continuous (TODO: own file `continuous_bandit.jl`)
S = state_space(mdp)

# Define the networks we will use
Qâ‚šâ‚šâ‚’() = Chain(x -> x ./ [6.3f0, 8f0], Dense(2, 64, relu), Dense(64, 64, relu), Dense(64, 1), x -> 200f0.*x .- 200f0)

# Randomly initialize critic network ğ‘„(s, a | Î¸á¶œ) and actor Î¼(s | Î¸áµ˜) with weights Î¸á¶œ and Î¸áµ˜
Q() = Chain(x -> x ./ [6.3f0, 8f0, 2f0], Dense(3, 64, relu), Dense(64, 64, relu), Dense(64, 1), x -> 200f0.*x .- 200f0) # NOTE change to 3: vcat(s,a)
Î¼() = Chain(x -> x ./ [6.3f0, 8f0], Dense(2, 64, relu), Dense(64, 64, relu), Dense(64, 1))
# Q() = Chain(Dense(2, 64, relu), Dense(64, 1))
# Q() = Chain(x->.-(x .- 2).^2)
# Î¼() = Chain(Dense(1, 64, relu), Dense(64, 1))

# Initialize target network ğ‘„â€² and Î¼â€² with weights Î¸á¶œâ€² âŸµ Î¸á¶œ, and Î¸áµ˜ âŸµ Î¸áµ˜
Qâ€²() = Q()
Î¼â€²() = Î¼()

# @info "Solving with PPO"
# ğ’®_ppo = PGSolver(Ï€=ActorCritic(GaussianPolicy(Î¼=Î¼(), logÎ£=zeros(Float32, 1)), Qâ‚šâ‚šâ‚’()),
#                  S=S, N=100000, Î”N=2048, loss=ppo(), opt=Flux.Optimiser(ClipNorm(1f0), ADAM(1e-3)),
#                  batch_size=512, epochs=100)
# Ï€_ppo = solve(ğ’®_ppo, mdp)

@info "Solving with DDPG"
ğ’®_ddpg = DDPGSolver(Ï€=ActorCritic(Î¼(), Q()) |> gpu,
                    Ï€â€²=ActorCritic(Î¼â€²(), Qâ€²()) |> gpu,
                    S=S, N=100_000)
Ï€_prev = deepcopy(ğ’®_ddpg.Ï€.A)
# ğ’®_ddpg = DDPGSolver(Ï€=ActorCritic(GaussianPolicy(Î¼=Î¼(), logÎ£=zeros(Float32, 1)), Q()),
#                     Ï€â€²=ActorCritic(GaussianPolicy(Î¼=Î¼â€²(), logÎ£=zeros(Float32, 1)), Qâ€²()),
#                     S=S, N=100_000, batch_size=512)
Ï€_ddpg = solve(ğ’®_ddpg, mdp)

# Plot the learning curve
# p = plot_learning([ğ’®_ppo, ğ’®_ddpg], title="Pendulum Swingup Training Curves", labels=["PPO", "DDPG"])
p = plot_learning([ğ’®_ddpg], title="Pendulum Swingup Training Curves", labels=["DDPG"])

# Produce a gif with the final policy
# gif(mdp, Ï€_ppo, "pendulum_ppo.gif", max_steps=200)
# gif(mdp, Ï€_ddpg, "pendulum_ddpg.gif", max_steps=200)

# Return plot
p
