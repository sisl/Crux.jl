@article{julia,
  title={Julia: A fresh approach to numerical computing},
  author={Jeff Bezanson and Alan Edelman and Stefan Karpinski and Viral B. Shah},
  journal={{SIAM Review}},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM},
  doi={10.1137/141000671}
}


@article{pomdps_jl,
  author  = {Maxim Egorov and Zachary N. Sunberg and Edward Balaban and Tim A. Wheeler and Jayesh K. Gupta and Mykel J. Kochenderfer},
  title   = {{{POMDP}s.jl: A framework for sequential decision making under uncertainty}},
  journal = {{Journal of Machine Learning Research}},
  year    = {2017},
  volume  = {18},
  number  = {26},
  pages   = {1-5}
}

@inproceedings{trpo,
  title={{Trust region policy optimization}},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={{International Conference on Machine Learning (ICML)}},
  pages={1889--1897},
  year={2015}
}

@article{ppo,
  title={{Proximal policy optimization algorithms}},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv:1707.06347},
  year={2017},
  doi={10.48550/arXiv.1707.06347}
}

@article{zeng2025reinforcement,
  title={{Reinforcement learning and metaheuristics for Feynman integral reduction}},
  author={Zeng, Mao},
  journal={arXiv:2504.16045},
  year={2025},
  doi={10.48550/arXiv.2504.16045}
}

@inproceedings{banerjee2024energy,
  title={{Energy-optimized path planning for UAS in varying winds via reinforcement learning}},
  author={Banerjee, Portia and Bradner, Kevin},
  booktitle={AIAA AVIATION FORUM and ASCEND},
  year={2024},
  doi={10.2514/6.2024-4545}
}

@book{valbook,
  title={{Algorithms for Validation}},
  author={Kochenderfer, Mykel J. and Katz, Sydney M. and Corso, Anthony L. and Moss, Robert J.},
  year={2026},
  publisher={MIT Press}
}

@article{flux,
  author    = {Mike Innes},
  title     = {{Flux: Elegant machine learning with Julia}},
  journal   = {Journal of Open Source Software},
  year      = {2018},
  volume    = {3},
  number    = {25},
  pages     = {602},
  publisher = {The Open Journal},
  doi       = {10.21105/joss.00602},
}

@article{dqn,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group},
  doi={10.1038/nature14236}
}

@inproceedings{td3,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{gym,
  title={Gymnasium: A standard interface for reinforcement learning environments},
  author={Towers, Mark and Kwiatkowski, Ariel and Terry, Jordan and Balis, John U. and De Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and Krimmel, Markus and KG, Arjun and others},
  journal={arXiv:2407.17032},
  year={2024},
  doi={10.48550/arXiv.2407.17032}
}

@article{reinforce,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J.},
  journal={Machine Learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer},
  doi={10.1007/BF00992696}
}

@article{sb3,
  title={Stable-baselines3: Reliable reinforcement learning implementations},
  author={Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={268},
  pages={1--8},
  year={2021}
}

@inproceedings{rllib,
    title={{RLlib}: Abstractions for Distributed Reinforcement Learning},
    author={
        Eric Liang and
        Richard Liaw and
        Robert Nishihara and
        Philipp Moritz and
        Roy Fox and
        Ken Goldberg and
        Joseph E. Gonzalez and
        Michael I. Jordan and
        Ion Stoica,
    },
    booktitle = {International Conference on Machine Learning ({ICML})},
    year={2018},
}