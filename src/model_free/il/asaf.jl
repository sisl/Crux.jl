function ASAF_actor_loss(Ï€G, ğ’Ÿ_demo)
    (Ï€, ğ’«, ğ’Ÿ,; info=Dict()) -> begin
        Ï€sa_G = logpdf(Ï€, ğ’Ÿ[:s], ğ’Ÿ[:a])
        Ï€sa_E = logpdf(Ï€, ğ’Ÿ_demo[:s], ğ’Ÿ_demo[:a])
        Ï€Gsa_G = logpdf(Ï€G, ğ’Ÿ[:s], ğ’Ÿ[:a])
        Ï€Gsa_E = logpdf(Ï€G, ğ’Ÿ_demo[:s], ğ’Ÿ_demo[:a])
        e = mean(entropy(Ï€, ğ’Ÿ[:s]))
        
        ignore() do
            info[:entropy] = e
        end 
        
        L = Flux.mean(log.(1 .+ exp.(Ï€Gsa_E - Ï€sa_E))) + Flux.mean(log.(exp.(Ï€sa_G - Ï€Gsa_G)  .+ 1))  - 0.1f0*e
        # if !isnothing(ğ’Ÿ_nda)
        #     Ï€sa_NDA = logpdf(Ï€, ğ’Ÿ_nda[:s], ğ’Ÿ_nda[:a])
        #     Ï€Gsa_NDA = logpdf(Ï€G, ğ’Ÿ_nda[:s], ğ’Ÿ_nda[:a])
        #     L += Flux.mean(log.(1 .+ exp.(Ï€sa_NDA - Ï€Gsa_NDA)))
        # end
        L
    end
end


function ASAF(;Ï€, 
               S, 
               ğ’Ÿ_demo, 
               normalize_demo::Bool=true, 
               Î”N=50, 
               Î»_orth=1f-4, 
               a_opt::NamedTuple=(;), 
               c_opt::NamedTuple=(;), 
               log::NamedTuple=(;), 
               kwargs...)
               
    normalize_demo && (ğ’Ÿ_demo = normalize!(deepcopy(ğ’Ÿ_demo), S, action_space(Ï€)))
    ğ’Ÿ_demo = ğ’Ÿ_demo |> device(Ï€)
    OnPolicySolver(;agent=PolicyParams(Ï€), 
                    S=S,
                    Î”N=Î”N,
                    post_batch_callback=(D; ğ’®, kwargs...) -> ğ’®.a_opt.loss = ASAF_actor_loss(deepcopy(ğ’®.agent.Ï€), ğ’Ÿ_demo),
                    log=LoggerParams(;dir="log/ASAF", period=100, log...),
                    a_opt=TrainingParams(;name="actor_", loss=nothing, a_opt...), 
                    kwargs...)
end

