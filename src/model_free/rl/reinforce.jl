# REINFORCE loss
function reinforce_loss(Ï€, ð’«, ð’Ÿ; info = Dict())
    new_probs = logpdf(Ï€, ð’Ÿ[:s], ð’Ÿ[:a])
    
    ignore() do
        info[:entropy] = mean(entropy(Ï€, ð’Ÿ[:s]))
        info[:kl] = mean(ð’Ÿ[:logprob] .- new_probs)
    end 
    
    -mean(new_probs .* ð’Ÿ[:return])
end

# Build a REINFORCE solver
function REINFORCE(;Ï€,
                    a_opt::NamedTuple=(;), 
                    log::NamedTuple=(;),
                    required_columns=[],
                    kwargs...)
                    
    OnPolicySolver(;agent=PolicyParams(Ï€),
                    log = LoggerParams(;dir = "log/reinforce", log...),
                    a_opt = TrainingParams(;loss = reinforce_loss, early_stopping = (infos) -> (infos[end][:kl] > 0.015), name = "actor_", a_opt...),
                    required_columns = unique([required_columns..., :return, :logprob]),
                    kwargs...)
end
        
    



