# REINFORCE loss
reinforce_loss() = (Ï€, ð’Ÿ; info = Dict()) -> reinforce_loss(Ï€, ð’Ÿ[:s], ð’Ÿ[:a], ð’Ÿ[:return], ð’Ÿ[:logprob], info)
function reinforce_loss(Ï€, s, a, G, old_probs, info = Dict())
    new_probs = logpdf(Ï€, s, a)
    
    ignore() do
        info[:entropy] = mean(entropy(Ï€, s))
        info[:kl] = mean(old_probs .- new_probs)
    end 
    
    -mean(new_probs .* G)
end

# Build a REINFORCE solver
REINFORCE(;a_opt::NamedTuple=(;), log::NamedTuple=(;), kwargs...) = 
    OnPolicySolver(;
        log = LoggerParams(;dir = "log/reinforce", log...),
        a_opt = TrainingParams(;loss = reinforce_loss(), early_stopping = (info) -> (info[:kl] > 0.015), name = "actor_", a_opt...),
        kwargs...)
    



