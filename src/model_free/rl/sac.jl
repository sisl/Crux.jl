function SAC_target(Ï€, Î±)
    (Ï€â», ğ’Ÿ, Î³; kwargs...) -> begin
        ap, logprob = exploration(Ï€.A, ğ’Ÿ[:sp])
        y = ğ’Ÿ[:r] .+ Î³ .* (1.f0 .- ğ’Ÿ[:done]) .* (min.(value(Ï€â», ğ’Ÿ[:sp], ap)...) .- Î±*logprob)
    end
end

function SAC_actor_loss(Î±)
    (Ï€, ğ’Ÿ; info = Dict()) -> begin
        a, logprob = exploration(Ï€.A, ğ’Ÿ[:s])
        mean(Î±*logprob .- min.(value(Ï€, ğ’Ÿ[:s], a)...))
    end
end

SAC(;Ï€::ActorCritic{T, DoubleNetwork{ContinuousNetwork, ContinuousNetwork}}, Î”N=50, Î±::Float32=0.2f0, Ï€_explore=GaussianNoiseExplorationPolicy(0.1f0), a_opt::NamedTuple=(;), c_opt::NamedTuple=(;), log::NamedTuple=(;), kwargs...) where T = 
    OffPolicySolver(;
        Ï€ = Ï€,
        Î”N=Î”N,
        log = LoggerParams(;dir = "log/sac", log...),
        a_opt = TrainingParams(;loss=SAC_actor_loss(Î±), name="actor_", a_opt...),
        c_opt = TrainingParams(;loss=double_Q_loss, name="critic_", epochs=Î”N, c_opt...),
        Ï€_explore = Ï€_explore,
        target_fn = SAC_target(Ï€, Î±),
        kwargs...)

