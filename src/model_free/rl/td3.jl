"""
TD3 target function.
"""
function td3_target(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; i)
    ap, _ = exploration(ğ’«[:Ï€_smooth], ğ’Ÿ[:sp], Ï€_on=Ï€, i=i)
    y = ğ’Ÿ[:r] .+ Î³ .* (1.f0 .- ğ’Ÿ[:done]) .* min.(value(Ï€, ğ’Ÿ[:sp], ap)...)
end

"""
TD3 actor loss function.
"""
td3_actor_loss(Ï€, ğ’«, ğ’Ÿ; info = Dict()) = -mean(value(Ï€.C.N1, ğ’Ÿ[:s], action(Ï€, ğ’Ÿ[:s])))

"""
Twin Delayed DDPG (TD3) solver.

```julia
TD3(;
    Ï€,
    Î”N=50,
    Ï€_smooth::Policy=GaussianNoiseExplorationPolicy(0.1f0, Ïµ_min=-0.5f0, Ïµ_max=0.5f0),
    Ï€_explore=GaussianNoiseExplorationPolicy(0.1f0),
    a_opt::NamedTuple=(;),
    c_opt::NamedTuple=(;),
    a_loss=td3_actor_loss,
    c_loss=double_Q_loss(),
    target_fn=td3_target,
    prefix="",
    log::NamedTuple=(;),
    ğ’«::NamedTuple=(;),
    kwargs...)
```
"""
function TD3(;
        Ï€,
        Î”N=50,
        Ï€_smooth::Policy=GaussianNoiseExplorationPolicy(0.1f0, Ïµ_min=-0.5f0, Ïµ_max=0.5f0),
        Ï€_explore=GaussianNoiseExplorationPolicy(0.1f0),
        a_opt::NamedTuple=(;),
        c_opt::NamedTuple=(;),
        a_loss=td3_actor_loss,
        c_loss=double_Q_loss(),
        target_fn=td3_target,
        prefix="",
        log::NamedTuple=(;),
        ğ’«::NamedTuple=(;),
        kwargs...)

    OffPolicySolver(;agent=PolicyParams(Ï€=Ï€, Ï€_explore=Ï€_explore, Ï€â»=deepcopy(Ï€)),
                     Î”N=Î”N,
                     ğ’«=(Ï€_smooth=Ï€_smooth, ğ’«...),
                     log=LoggerParams(;dir = "log/td3", log...),
                     a_opt=TrainingParams(;loss=a_loss, name=string(prefix, "actor_"), a_opt...),
                     c_opt=TrainingParams(;loss=c_loss, name=string(prefix, "critic_"), epochs=Î”N, c_opt...),
                     target_fn=target_fn,
                     kwargs...)
end
