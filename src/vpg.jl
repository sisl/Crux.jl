@with_kw mutable struct VPGSolver <: Solver 
    Ï€::Policy
    baseline::Union{Baseline, Nothing}
    N::Int64
    buffer_size::Int = 1000
    batch_size::Int = 32
    max_steps::Int64 = 100
    opt = ADAM(1e-3)
    device = cpu
    rng::AbstractRNG = Random.GLOBAL_RNG
    log = LoggerParams(dir = "log/vpg", period = 500)
    i::Int64 = 1
end

vpg_loss(Ï€, ğ’Ÿ) = -mean(logpdf(Ï€, ğ’Ÿ[:s], ğ’Ÿ[:a]) .* ğ’Ÿ[:advantage])

function POMDPs.solve(ğ’®::VPGSolver, mdp)
    # Log the pre-train performance
    ğ’®.i == 0 && log(ğ’®.log, ğ’®.i, log_discounted_return(mdp, ğ’®.Ï€, ğ’®.rng))
    
    ğ’Ÿ = ExperienceBuffer(mdp, ğ’®.buffer.size, device = ğ’®.device, gae = true, Nelements = ğ’®.buffer.size)
    Î”N = length(ğ’Ÿ)
    
    ğ’®.i == 1 && log(ğ’®.log, 0, mdp, ğ’®.Ï€, rng = ğ’®.rng)
    for ğ’®.i = Î”N+ğ’®.i : Î”N : ğ’®.i + ğ’®.N - 1
        fill!(ğ’Ÿ, mdp, ğ’®.Ï€, baseline = ğ’®.baseline, max_steps = ğ’®.max_steps, rng = ğ’®.rng) # Sample episodes
        !isnothing(ğ’®.baseline) && train!(ğ’®.baseline, ğ’Ÿ) # train baseline
        loss, grad = train!(ğ’®.Ï€, () -> vpg_loss(ğ’®.Ï€, ğ’Ÿ), ğ’®.opt, ğ’®.device) # train vpg
        log(ğ’®.log, ğ’®.i, mdp, ğ’®.Ï€, data = [logloss(loss, grad)], rng = ğ’®.rng, last_i = ğ’®.i-Î”N)
    end
end

