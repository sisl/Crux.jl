using Crux, Flux, POMDPGym, Random, POMDPs

expert_buffer_size = 1000

## Cartpole - V0 (For DQN-GAIL)
mdp = GymPOMDP(:CartPole, version = :v0)
as = actions(mdp)
S = state_space(mdp)

Q() = Chain(Dense(dim(S)..., 64, relu), Dense(64, 64, relu), Dense(64, length(as)))
D_DQN() = Chain(Dense(dim(S)..., 64, relu), Dense(64, 64, relu), Dense(64, length(as), sigmoid))
D_PG() = Chain(Dense(dim(S)[1] + length(as), 64, relu), Dense(64, 64, relu), Dense(64, 1, sigmoid))
V() = Chain(Dense(dim(S)..., 64, relu), Dense(64, 64, relu), Dense(64, 1))
A() = Chain(Dense(dim(S)..., 64, relu), Dense(64, 64, relu), Dense(64, length(as)), softmax)

# Solve with DQN
ğ’®_dqn = DQNSolver(Ï€ = DQNPolicy(Q(), as), S = S, N=1000)
Ï€_dqn = solve(ğ’®_dqn, mdp)

# Fill a buffer with expert trajectories
expert_trajectories = ExperienceBuffer(steps!(Sampler(mdp = mdp, S = S, A = action_space(Ï€_dqn), Ï€ = Ï€_dqn), Nsteps = expert_buffer_size))
sum(expert_trajectories[:r])


# Solve with DQN - GAIL
ğ’®_gail = GAILSolver(D = D_DQN(), 
                    G = DQNSolver(Ï€ = DQNPolicy(Q(), as), S = S, N=1000),
                    expert_buffer = expert_trajectories)
solve(ğ’®_gail, mdp)

# Solve with PPO - GAIL
ğ’®_ppo = PGSolver(Ï€ = ActorCritic(CategoricalPolicy(A(), as), V()), 
                S = S, N=1000, Î”N = 100, loss = ppo())
ğ’®_gail = GAILSolver(D = D_PG(), 
                    G = ğ’®_ppo,
                    expert_buffer = expert_trajectories)
solve(ğ’®_gail, mdp)

